# 1장 크롤링/스크롤링

# urlopen() & read()

```python
import urllib.request

url = "http://uta.pw/shodou/img/28/214.png"
savename = "test.png"

urllib.request.urlretrieve(url, savename)
```

```python
import urllib.request

url = "http://uta.pw/shodou/img/28/214.png"
savename = "test.png"

# download

mem = urllib.request.urlopen(url).read()

with open(savename, mode="wb") as f:
    f.write(mem)
    print("saved")
```

- `wb` 모드로 바이너리를 단순하게 써봤음

```python
import urllib.request

url = "https://www.google.co.kr/"
mem = urllib.request.urlopen(url).read()
print(mem.decode("euc-kr"))
```

# 매개변수를 추가해 요청을 전송하는 방법

- 스크래핑을 할때는 서버가 어떻게 구성되어 있는지 알아야한다.

## 예제

[https://search.naver.com/search.naver?sm=top_hty&fbm=1&ie=utf8&query=바보](https://search.naver.com/search.naver?sm=top_hty&fbm=1&ie=utf8&query=%EB%B0%94%EB%B3%B4)

방식:  GET, POST, PUT, DELETE

대상:[search.naver.com](http://search.naver.com/) ⇒ 호스트 이름

추가적인 정보: 

- 경로 :/search.naver
- 요청매개변수:  [key] = [value] 의 형태
    - [?](https://www.google.co.kr/search?q=%EB%84%A4%EC%9D%B4%EB%B2%84&rlz=1C1SQJL_koKR828KR828&oq=%EB%84%A4%EC%9D%B4%EB%B2%84&aqs=chrome..69i57j69i65l2j69i61l3.1917j0j4&sourceid=chrome&ie=UTF-8)sm=top
    - [&](https://www.google.co.kr/search?q=%EB%84%A4%EC%9D%B4%EB%B2%84&rlz=1C1SQJL_koKR828KR828&oq=%EB%84%A4%EC%9D%B4%EB%B2%84&aqs=chrome..69i57j69i65l2j69i61l3.1917j0j4&sourceid=chrome&ie=UTF-8)fbm=1
    - [&](https://www.google.co.kr/search?q=%EB%84%A4%EC%9D%B4%EB%B2%84&rlz=1C1SQJL_koKR828KR828&oq=%EB%84%A4%EC%9D%B4%EB%B2%84&aqs=chrome..69i57j69i65l2j69i61l3.1917j0j4&sourceid=chrome&ie=UTF-8)ie=utf8
    - [&](https://www.google.co.kr/search?q=%EB%84%A4%EC%9D%B4%EB%B2%84&rlz=1C1SQJL_koKR828KR828&oq=%EB%84%A4%EC%9D%B4%EB%B2%84&aqs=chrome..69i57j69i65l2j69i61l3.1917j0j4&sourceid=chrome&ie=UTF-8)query=바보

## 파이썬으로 요청해보기

```python
import urllib.request
import urllib.parse

full = "https://search.naver.com/search.naver?sm=top_hty&fbm=1&ie=utf8&query=%EB%B0%94%EB%B3%B4"
api = "https://search.naver.com/search.naver"
values = {
    "sm":"top_hty",
    "fbm": "1",
    "ie": "utf8",
    "query": "%EB%B0%94%EB%B3%B4"
}

params = urllib.parse.urlencode(values)

url = api + "?" + params 
data = urllib.request.urlopen(url).read()
text = data.decode("utf-8")
print(text)
```

# Beautiful Soup 설치

## CSS

### 태그 선택자

`"hl"` `"html"`

### 아이디 선택자

`"#<아이디 이름>"`

### 클래스 선택자

`".<클래스 이름>.<클래스 이름>"`

### 후손 선택자

`"#meigan li"`

### 자식 선택자

`"ul.items > li"`

```python
from bs4 import BeautifulSoup

html = """"""
soup = BeautifulSoup(html, "html.parser")

header = soup.select_one("body > div > h1")  # element 
list_items = soup.select("ul.items > li")    # array of element

header.string
soup.select_one("ul").attrs

for li in list_items:
    li.string
```

```python
import urllib.request
from bs4 import BeautifulSoup

url = "https://finance.naver.com/marketindex/"
response = urllib.request.urlopen(url)

soup = BeautifulSoup(response, "html.parser")
prices = soup.select("span.value")

for price in prices:
    print("usd/kw = ", price.string)
```

```python
import urllib.request
from bs4 import BeautifulSoup

url = "https://news.naver.com/main/main.nhn?mode=LSD&mid=shm&sid1=105"
response = urllib.request.urlopen(url)

soup = BeautifulSoup(response, "html.parser")
results = soup.select(".cluster_text_headline")

for result in results:
    print(result.string)
```

### IT TOP10 기사 가져오기

```python
import urllib.request
from bs4 import BeautifulSoup
from operator import eq

host = "https://news.naver.com"
url = host + "/main/main.nhn?mode=LSD&mid=shm&sid1=105"
response = urllib.request.urlopen(url)

soup = BeautifulSoup(response, "html.parser")
results = soup.select(".section_list_ranking > li > a")

i = 1

for result in results:
    print(result.attrs["class"])
    if eq(result.attrs["class"][0],"nclicks(rig.ranksci)"):
        print(str(i) + " : " + result.attrs["title"])
        print("link : " + host + result.attrs["href"])
        i = i + 1
```

### IT TOP10 기사 가져오기 ver 2

```python
import urllib.request
from bs4 import BeautifulSoup
from operator import eq

# setting
def get_soup(url):
    response = urllib.request.urlopen(url)
    soup = BeautifulSoup(response, "html.parser")
    return soup

# find ranked article headline 
def get_rank_list(category):
    soup = get_soup(url)
    rank_total = soup.select(".section_list_ranking > li > a")
    rank_class_name = "nclicks(rig.rank" + category + ")"
    
    result = []
    for rank_element in rank_total:
        if eq(rank_element["class"][0], rank_class_name):
            result.append(rank_element)
    
    return result

# print ranked article
def print_rank_list(category):
    host = "https://news.naver.com"

    rank_list = get_rank_list(category)

    rank = 1 
    for article in rank_list:
        print(str(rank) + " : " + article["title"])
        print("link : " + host + article["href"])
        print()
        rank += 1
    return

host = "https://news.naver.com"
url = host + "/main/main.nhn?mode=LSD&mid=shm&sid1=105"
category = "sci"

print_rank_list(category)
```