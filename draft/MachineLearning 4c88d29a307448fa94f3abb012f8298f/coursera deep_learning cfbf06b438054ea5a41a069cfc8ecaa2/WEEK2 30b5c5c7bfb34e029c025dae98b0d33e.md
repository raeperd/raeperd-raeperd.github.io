# WEEK2

# Logistic Regression as a Neural Network

![WEEK2%2030b5c5c7bfb34e029c025dae98b0d33e/Untitled.png](WEEK2%2030b5c5c7bfb34e029c025dae98b0d33e/Untitled.png)

- Loss function 은 하나의 data에 대한 함수
- cost function 은 weight에 대한 함수

![WEEK2%2030b5c5c7bfb34e029c025dae98b0d33e/Untitled%201.png](WEEK2%2030b5c5c7bfb34e029c025dae98b0d33e/Untitled%201.png)

- chain rule을 이용해 cost function의 편미분 값을 계산할 수 있다.

![WEEK2%2030b5c5c7bfb34e029c025dae98b0d33e/Untitled%202.png](WEEK2%2030b5c5c7bfb34e029c025dae98b0d33e/Untitled%202.png)

![WEEK2%2030b5c5c7bfb34e029c025dae98b0d33e/Untitled%203.png](WEEK2%2030b5c5c7bfb34e029c025dae98b0d33e/Untitled%203.png)

read Right to Left

- dz is obtained by da/dz and da with chain-rule
- dw1 and dw2 is obtained by dz

![WEEK2%2030b5c5c7bfb34e029c025dae98b0d33e/Untitled%204.png](WEEK2%2030b5c5c7bfb34e029c025dae98b0d33e/Untitled%204.png)

- do not explicit for-loop use vectorization version

---

# Python and Vectorization

![WEEK2%2030b5c5c7bfb34e029c025dae98b0d33e/Untitled%205.png](WEEK2%2030b5c5c7bfb34e029c025dae98b0d33e/Untitled%205.png)

![WEEK2%2030b5c5c7bfb34e029c025dae98b0d33e/Untitled%206.png](WEEK2%2030b5c5c7bfb34e029c025dae98b0d33e/Untitled%206.png)

- Whenever possible, avoid explicit for-loops.
- 

![WEEK2%2030b5c5c7bfb34e029c025dae98b0d33e/Untitled%207.png](WEEK2%2030b5c5c7bfb34e029c025dae98b0d33e/Untitled%207.png)

- optimizing for-loop is still needed

### Vectorizing Logistic Regression

### Vectorizing Logistic Regression's Gradient Output

![WEEK2%2030b5c5c7bfb34e029c025dae98b0d33e/Untitled%208.png](WEEK2%2030b5c5c7bfb34e029c025dae98b0d33e/Untitled%208.png)

![WEEK2%2030b5c5c7bfb34e029c025dae98b0d33e/Untitled%209.png](WEEK2%2030b5c5c7bfb34e029c025dae98b0d33e/Untitled%209.png)

- Gradient descent를 반복하기위해서는 여전히 for-loop 가 필요하다.

## Broadcasting in Python

### Broadcasting example

- reshape는 필요없지만 코드의 확신을 얻기 위해 사용한다.
- constant time operation 임

![WEEK2%2030b5c5c7bfb34e029c025dae98b0d33e/Untitled%2010.png](WEEK2%2030b5c5c7bfb34e029c025dae98b0d33e/Untitled%2010.png)

Matlab/Octave: bsxfun

### A note on python/numpy vectors

```python
a = np.random.radn(5)   # do not use this
a = np.random.radn(5,1)
a = np.random.radn(1,5)
```